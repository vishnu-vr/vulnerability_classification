import json
import os
from sklearn.model_selection import train_test_split
import pandas as pd
import numpy as np
import helper_functions as help
from sklearn.metrics import confusion_matrix, f1_score
# import matplotlib.pyplot as plot
# import pandas as pd
# from tensorflow.python.keras.preprocessing.text import Tokenizer
# import heapq

'''###########################fetching data##########################'''
# dataset path
# clean
clean_des = json.load(open("/Users/vishnu/Desktop/project/clean_cve/shuffled_clean/shuffled_combined_description_after_stemming.json"))
clean_labels = json.load(open("/Users/vishnu/Desktop/project/clean_cve/shuffled_clean/shuffled_labels.json"))
# converting labels to integers
clean_labels = np.array(pd.get_dummies(clean_labels)).argmax(-1)

# dirty
dirty_des = json.load(open("/Users/vishnu/Desktop/project/dirty_cve/shuffled_dirty/shuffled_combined_description_after_stemming_dirty.json"))
dirty_labels = json.load(open("/Users/vishnu/Desktop/project/dirty_cve/shuffled_dirty/shuffled_labels.json"))
# converting labels to integers
dirty_labels = np.array(pd.get_dummies(dirty_labels)).argmax(-1)


# path of predictions
# clean
clean_pred_path = "/Users/vishnu/Desktop/project/new_3/predictions/clean/clean_all"
# dirty
dirty_pred_path = "/Users/vishnu/Desktop/project/new_3/predictions/dirty/dirty_all"
'''###########################fetching data##########################'''


'''data for plotting pie chart and confusion matrix'''
# # clean
# list_pie,list_con_mat = help.confusion_and_pie_data(clean_des,clean_labels,clean_pred_path)
# # dirty
# # list_pie,list_con_mat = help.confusion_and_pie_data(dirty_des,dirty_labels,dirty_pred_path)


'''plotting pie charts'''
# plotting actual
# help.plot_pie(list_pie[0])
# plotting misclassified
# help.plot_pie(list_pie[1])

'''plotting confusion heat_map'''
# # confusion matrix
# con_mat = confusion_matrix(list_con_mat[0], list_con_mat[1])
# # plotting heat map
# help.heat_map(con_mat)


'''finding the similarity between misclassified test and train (HEAT MAP)'''
# # '''data for plotting pie chart and confusion matrix'''
# # clean
# # list_pie,list_con_mat = help.confusion_and_pie_data(clean_des,clean_labels,clean_pred_path)
# # dirty
# list_pie,list_con_mat = help.confusion_and_pie_data(dirty_des,dirty_labels,dirty_pred_path)

# # '''plotting confusion heat_map'''
# # confusion matrix
# con_mat = confusion_matrix(list_con_mat[0], list_con_mat[1])

# # initializing empty sim_matrix
# sim_mat = []
# for i in range(13):
# 	sim_mat.append([0 for i in range(13)])

# for test_class,test in enumerate(con_mat):
# 	# getting the indices of top two values
# 	# train_indices is a list containing
# 	# largest and second largest indices
# 	# respectively
# 	train_indices = help.get_ind_larg_two(test)
# 	for train_class in train_indices:
# 		if test_class == train_class:
# 			continue
# 		print(str(test_class)+" : "+str(train_class))
# 		# fetching misclassified test data
# 		test_data = help.get_misclassified_test_data(test_class,train_class,dirty_pred_path,dirty_des,dirty_labels)
# 		# converting to a list of strings manner
# 		# and then to a giant string
# 		test_data = ' '.join(help.convertData(test_data))
# 		# fetching train data
# 		train_data = help.get_train_data(train_class,dirty_des,dirty_labels)
# 		# generating summary which is of manner - list of strings
# 		# then to a giant string
# 		train_summary = ' '.join(help.summarizer(train_data))
# 		# getting cosine similarity
# 		similarity = help.get_cosine_sim(train_summary,test_data)[0][1]

# 		sim_mat[test_class][train_class] = round(similarity*100)

# help.heat_map(sim_mat,percentage=False)


'''finding the similarity between misclassified test and train (multi-bar bar chart)'''
# # '''data for plotting pie chart and confusion matrix'''
# # clean
# list_pie,list_con_mat = help.confusion_and_pie_data(clean_des,clean_labels,clean_pred_path)
# # dirty
# # list_pie,list_con_mat = help.confusion_and_pie_data(dirty_des,dirty_labels,dirty_pred_path)

# # '''plotting confusion heat_map'''
# # confusion matrix
# con_mat = confusion_matrix(list_con_mat[0], list_con_mat[1])

# # # initializing empty sim_dic
# # sim_dic = {}
# # for i in range(13):
# # 	sim_dic[i] = []

# list_1 = []
# list_2 = []
# list_1_class_no = []
# list_2_class_no = []
# for test_class,test in enumerate(con_mat):
# 	# getting the indices of top two values
# 	# train_indices is a list containing
# 	# largest and second largest indices
# 	# respectively
# 	train_indices = help.get_ind_larg_two(test)
# 	for list_num,train_class in enumerate(train_indices):

# 		if test_class == train_class:
# 			continue

# 		print(str(test_class)+" : "+str(train_class))
# 		# fetching misclassified test data
# 		test_data = help.get_misclassified_test_data(test_class,train_class,clean_pred_path,clean_des,clean_labels)
# 		# converting to a list of strings manner
# 		# and then to a giant string
# 		test_data = ' '.join(help.convertData(test_data))
# 		# fetching train data
# 		train_data = help.get_train_data(train_class,clean_des,clean_labels)
# 		# generating summary which is of manner - list of strings
# 		# then to a giant string
# 		train_summary = ' '.join(help.summarizer(train_data))
# 		# getting cosine similarity
# 		similarity = help.get_cosine_sim(train_summary,test_data)[0][1]

# 		similarity = round(similarity*100)

# 		if list_num == 0:
# 			list_1.append(similarity)
# 			list_1_class_no.append(train_class)
# 		else:
# 			list_2.append(similarity)
# 			list_2_class_no.append(train_class)

# 		# sim_dic[test_class].append((train_class,similarity))

# help.plot_hbar(list_1,list_2,list_1_class_no+list_2_class_no)






















