#sim is 103 for http_response_splitting :165 / 165 || cross_site_scripting :15046 / 15046
'''
http overlaps with the following classes with 60 and more than 60 percent similarity

{'code_execution': 6,
 'dos': 3,
 'overflow': 0,
 'gain_information': 26,
 'sql_injection': 5,
 'bypass': 6,
 'memory_corruption': 0,
 'gain_privilege': 0,
 'directory_traversal': 2,
 'csrf': 0,
 'file_inclusion': 0
 'cross_site_scripting': 103}

'''
'''
http overlaps with the following classes this many times

{'code_execution': 1,
 'dos': 2,
 'overflow': 0,
 'cross_site_scripting': 23,
 'gain_information': 6,
 'sql_injection': 2,
 'bypass': 3,
 'memory_corruption': 0,
 'gain_privilege': 0,
 'directory_traversal': 0,
 'csrf': 0,
 'file_inclusion': 0}
'''


import pandas as pd
import sys

def lev_dis(source, target):
    if source == target:
        return 100

    length = len(source) if len(source)>len(target) else len(target)

    # Prepare a matrix
    slen, tlen = len(source), len(target)
    dist = [[0 for i in range(tlen+1)] for x in range(slen+1)]
    for i in range(slen+1):
        dist[i][0] = i
    for j in range(tlen+1):
        dist[0][j] = j

    # Counting distance, here is my function
    for i in range(slen):
        for j in range(tlen):
            cost = 0 if source[i] == target[j] else 1
            dist[i+1][j+1] = min(
                            dist[i][j+1] + 1,   # deletion
                            dist[i+1][j] + 1,   # insertion
                            dist[i][j] + cost   # substitution
                        )

    # number of edits required to make the two strings same
    ret = dist[-1][-1]

    # finding similarity
    return 100 - int((ret/length)*100)

#target = {}
c={}
def pp(data):
	global sim

	global c#={}

	source = [ele.strip() for ele in list(data["http_response_splitting"])]

	#target = [ele.strip() for ele in list(data["code_execution"])]

	target = {}

	for name,des in data.items():
		if name == "http_response_splitting":
			continue
		target[name] = [ele.strip() for ele in des]

	for t_name in list(target.keys()):
		c[t_name]=0

	for s in source:
		for t_name,t_des in target.items():
			if s in t_des:
				c[t_name]+=1



	#print(c)
	


sim={}
def find_similarity(data):
	'''
	data : dictionary contains names as keys and corresponding csv(dataframe)
		   as values
	'''
	
	global sim


	source = [ele.strip().split() for ele in data["http_response_splitting"]] #source is http_res
	#target = [ele.strip().split() for ele in list(data.values())[0]]

	target={}

	for name,des in data.items():
		# skipping http_response and xss cause
		# http is the source and we have already found the 
		# results of xss
		if name == "http_response_splitting" or name == "cross_site_scripting":
			continue
		target[name] = [d.strip().split() for d in des]
		sim[name]=0

	s_name = "http_response_splitting"
	s_name += " :"
	#t_name = list(data.keys())[0]
	#t_name += " :"

	#print(type(code))
	#print(type(dos))
	#sys.exit(0)

	length_s = str(len(source))
	#length_t = str(len(target))

	s_no=0
	for s in source:
		s_no+=1
		#if s_no < 37:
		#	continue
		#code_des = code_des.strip()
		for t_name,t_des in target.items():
			print(s_name+str(s_no)+" / "+length_s+" || "+t_name)
			#t_no=0
			#length_t=str(len(t_des))
			for t in t_des:
				#t_no+=1
				#print(s_name+str(s_no)+" / "+length_s+" || "+t_name+" :"+str(t_no)+" / "+length_t)

				lev = lev_dis(s,t)
				#print(lev)
				if lev > 60:
					print("im in")
					sim[t_name]+=1
					#print(sim)
					#break
					#sys.exit(0)



def readCve():
	
	loc = ['/Users/vishnu/Desktop/project/dataset/code_execution.csv',
			'/Users/vishnu/Desktop/project/dataset/dos.csv',
			'/Users/vishnu/Desktop/project/dataset/overflow.csv',
			'/Users/vishnu/Desktop/project/dataset/cross_site_scripting.csv',
			'/Users/vishnu/Desktop/project/dataset/gain_information.csv',
			'/Users/vishnu/Desktop/project/dataset/sql_injection.csv',
			'/Users/vishnu/Desktop/project/dataset/bypass.csv',
			'/Users/vishnu/Desktop/project/dataset/memory_corruption.csv',
			'/Users/vishnu/Desktop/project/dataset/gain_privilege.csv',
			'/Users/vishnu/Desktop/project/dataset/directory_traversal.csv',
			'/Users/vishnu/Desktop/project/dataset/csrf.csv',
			'/Users/vishnu/Desktop/project/dataset/file_inclusion.csv',
			'/Users/vishnu/Desktop/project/dataset/http_response_splitting.csv']

	

	
	#loc = ['/Users/vishnu/Desktop/project/dataset/cross_site_scripting.csv',
	#		'/Users/vishnu/Desktop/project/dataset/http_response_splitting.csv']

	
	names = ['code_execution',
				'dos',
				'overflow',
				'cross_site_scripting',
				'gain_information',
				'sql_injection',
				'bypass',
				'memory_corruption',
				'gain_privilege',
				'directory_traversal',
				'csrf',
				'file_inclusion',
				'http_response_splitting']
	

	#names = ['cross_site_scripting',
	#		'http_response_splitting']

	data=[]
	for ele in loc:
		data.append(pd.read_csv(ele)["description"])

	data_dic = dict(zip(names,data))


	print("reading complete")

	return data_dic



find_similarity(readCve())





